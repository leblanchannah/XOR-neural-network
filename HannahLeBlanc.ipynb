{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Partial derivative $\\frac{\\partial J(\\vect{x})}{\\partial w_{j,i}^{(1)}}$ of the cost function $J(\\vect{x})$ with respect to weight $w_{j,i}^{(1)}$ between input $\\vect{x_{i}}$ and the hidden unit $h_{j}^{1}$ for a 2 hidden layer (k=2) neural network with sigmoid activation functions. \n",
    "\n",
    "\n",
    "$\\newcommand{\\vect}[1]{\\boldsymbol{#1}} $\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\frac{\\partial J(\\vect{x})}{\\partial w_{j,i}^{(1)}} & = \\frac{\\partial (f(\\vect{x})-y)^2}{\\partial w_{j,i}^{(1)}}\\\\\n",
    "& = 2(f(\\vect{x})-y) \\frac{\\partial f(\\vect{x})}{\\partial w_{j,i}^{(1)}} \\\\ \n",
    "& = 2(f(\\vect{x})-y)f(\\vect{x})(1-(f(\\vect{x}))) \\frac{\\partial \\sum_{l=1}^{L} w_{l}h_{l}^{(2)} + b}{\\partial w_{j,i}^{(1)}}\\\\\n",
    "& = 2(f(\\vect{x})-y)f(\\vect{x})(1-(f(\\vect{x})))w_{i}\\frac{\\partial h_{i}^{(2)}}{\\partial w_{j,i}^{(1)}}\\\\\n",
    "& = 2(f(\\vect{x})-y)f(\\vect{x})(1-(f(\\vect{x})))w_{i}h_{i}^{(2)}(1-h_{i}^{(2)}) \\frac{\\partial \\sum_{m=1}^{M} w_{k,i}^{(2)}h_{k}^{(1)} + b_{i}^{(2)}}{\\partial w_{j,i}^{(1)}}\\\\\n",
    "& = 2(f(\\vect{x})-y)f(\\vect{x})(1-(f(\\vect{x})))w_{i}h_{i}^{(2)}(1-h_{i}^{(2)})w_{j,i}^{(2)} \\frac{\\partial h_{i}^{(i)}}{\\partial w_{j,i}^{(1)}} \\\\\n",
    "& = 2(f(\\vect{x})-y)f(\\vect{x})(1-(f(\\vect{x})))w_{i}h_{i}^{(2)}(1-h_{i}^{(2)})w_{j,i}^{(2)}h_{i}^{(1)}(1-h_{i}^{(1)})\\frac{\\partial \\sum_{n=1}^{N} w_{n,i}^{(1)}\\vect{x_{k}} + b_{i}^{(1)}}{\\partial w_{j,i}^{(1)}}\\\\\n",
    "& = 2(f(\\vect{x})-y)f(\\vect{x})(1-(f(\\vect{x})))w_{i}h_{i}^{(2)}(1-h_{i}^{(2)})w_{j,i}^{(2)}h_{i}^{(1)}(1-h_{i}^{(1)})\\vect{x_{j}}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "* Line 1 by definition of $J(\\vect{x})$\n",
    "* Line 2 derivative of a polynomial and chain rule\n",
    "* Line 3 derivative of sigmoid function and chain rule applied to activation funtion on output layer\n",
    "* Line 4 derivative of hidden layer 2\n",
    "* Line 5 derivative of sigmoid and second hidden layer\n",
    "* Line 6 derivative of hidden layer 1\n",
    "* Line 7 derivative of sigmoid and first hidden layer\n",
    "* Line 8 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hannah LeBlanc (10091837) CISC873 Deep Learning\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=1 hidden layer neural network\n",
    "class Network:\n",
    "    def __init__(self, alpha, inputUnits, hiddenUnits):\n",
    "        #setting seed so that initalized weights are consistent\n",
    "        np.random.seed(3)\n",
    "        # np.zeros and np.random.randn both return type ndarray\n",
    "        self.W1 = np.random.rand(inputUnits,hiddenUnits)\n",
    "        self.b1 = np.zeros((1,hiddenUnits))\n",
    "        self.W =  np.random.randn(hiddenUnits,1)\n",
    "        self.b = np.zeros((1, 1))\n",
    "        # learning rate\n",
    "        self.alpha = alpha\n",
    "        self.printParams()\n",
    "        \n",
    "    # activation function    \n",
    "    def sigmoid(self,x):\n",
    "        return 1.0/(1.0 + np.exp(-x))\n",
    "    \n",
    "    # activation function derivative\n",
    "    def sigmoidDerivative(self, x):\n",
    "        return x * (1.0 - x)\n",
    "        \n",
    "    # M x N array = X, (4x2)\n",
    "    # M dim array = y, (4x1)\n",
    "    def train(self, X, y):\n",
    "        self.forwardPropagation(X)\n",
    "        error = np.absolute(self.output-y)\n",
    "        self.backPropagation(X,y)\n",
    "        return error\n",
    "    \n",
    "    # M x N array = X, (4x2)\n",
    "    # output is a 4 x 1 ndarray\n",
    "    # uses sigmoid as activation function\n",
    "    def forwardPropagation(self, x):\n",
    "        self.z1 = np.dot(x,self.W1) + self.b1\n",
    "        self.hidden = self.sigmoid(self.z1)\n",
    "        self.z2 = np.dot(self.hidden,self.W) + self.b\n",
    "        self.output = self.sigmoid(self.z2) # Final output prediction\n",
    "    \n",
    "    # x = 4 x 2\n",
    "    # y = 4 x 1\n",
    "    def backPropagation(self,x,y):\n",
    "        h = self.hidden # 4 x 2\n",
    "        fx = self.output # 4 x 1\n",
    "    \n",
    "        #weight partial derivs\n",
    "        self.dW = np.dot(h.T, (2*(y - fx) * self.sigmoidDerivative(fx)))\n",
    "        self.dW1 = np.dot(x.T,  (np.dot(2*(y - fx) * self.sigmoidDerivative(fx), self.W.T) * self.sigmoidDerivative(h)))\n",
    "        \n",
    "        #bias partial derivs\n",
    "        db =  (2*(y - fx) * self.sigmoidDerivative(fx))\n",
    "        db1 = (np.dot(2*(y - fx) * self.sigmoidDerivative(fx), self.W.T) * self.sigmoidDerivative(h))\n",
    "        \n",
    "        # update weights with gradient \n",
    "        self.W1 = self.W1 + self.alpha * self.dW1 # 2 x 2 \n",
    "        self.b1 = self.b1 + self.alpha * db1 # 1 x 2\n",
    "        self.W = self.W + self.alpha * self.dW # 2 x 1\n",
    "        self.b = self.b + self.alpha * db # 1 x 1\n",
    "        \n",
    "    def predict(self, X):\n",
    "        self.forwardPropagation(X)\n",
    "        return self.output\n",
    "\n",
    "    def printParams(self):\n",
    "        print(\"Learning Rate: \",self.alpha)\n",
    "        print(\"W1: \", self.W1.shape)\n",
    "        print(self.W1)\n",
    "        print(\"b1: \", self.b1.shape)\n",
    "        print(self.b1)\n",
    "        print(\"W: \", self.W.shape)\n",
    "        print(self.W)\n",
    "        print(\"b: \", self.b.shape)\n",
    "        print(self.b)\n",
    "        \n",
    "    def testNNClass(self):\n",
    "        print(self.sigmoid(np.array([[0,0,0,0]]).T))\n",
    "        print(self.sigmoid(np.array([[0,0,0,0]])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training neural network on XOR problem ($M = 4$ binary input patterns of length $N = 2$) until $|f(\\vect x^{p}) - y^{p}| < 0.4$ for all p.\n",
    "\n",
    "Currently $J(\\vect x)$ is commented out because train runs for many iterations. Predicted patterns are printed along with actual labels. Ideally a step function should be used at the end so that the output prediction would match the same classes as labels. Using a learning rate of 0.001 and 2 units in hidden layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate:  0.001\n",
      "W1:  (2, 2)\n",
      "[[0.5507979  0.70814782]\n",
      " [0.29090474 0.51082761]]\n",
      "b1:  (1, 2)\n",
      "[[0. 0.]]\n",
      "W:  (2, 1)\n",
      "[[-0.2773882 ]\n",
      " [-0.35475898]]\n",
      "b:  (1, 1)\n",
      "[[0.]]\n",
      "Epochs:  2397\n",
      "Hidden layer size:  2\n",
      "\n",
      "PREDICTED\n",
      "[[0.60007699]\n",
      " [0.35825711]\n",
      " [0.60222078]\n",
      " [0.35053803]]\n",
      "ACTUAL\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# train and test values\n",
    "X = np.array([[1,0],[0,0],[0,1],[1,1]]) # MxN = 4X2\n",
    "y = np.array([[1,0,1,0]]).T\n",
    "\n",
    "# error threshold \n",
    "error_t = 0.4\n",
    "error = 1\n",
    "hiddenNodes = 2\n",
    "numIterations = 100000\n",
    "i=0\n",
    "\n",
    "# #alpha, input, hidden\n",
    "q2 = Network(0.001,2,hiddenNodes)\n",
    "# while less than max iterations and all training samples have an error greater than 0.4\n",
    "while i < numIterations and np.greater(error,error_t).any():\n",
    "    error = q2.train(X, y)\n",
    "    #cost = np.sum(np.power(error,2),axis=0)\n",
    "    #print(cost)\n",
    "    i += 1\n",
    "\n",
    "# confirming that the correct patterns are predicted for the four test cases    \n",
    "print(\"Epochs: \",i)\n",
    "print(\"Hidden layer size: \",hiddenNodes)\n",
    "print()\n",
    "print(\"PREDICTED\")\n",
    "print(q2.predict(X))\n",
    "print(\"ACTUAL\")\n",
    "print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate:  0.001\n",
      "W1:  (2, 8)\n",
      "[[0.5507979  0.70814782 0.29090474 0.51082761 0.89294695 0.89629309\n",
      "  0.12558531 0.20724288]\n",
      " [0.0514672  0.44080984 0.02987621 0.45683322 0.64914405 0.27848728\n",
      "  0.6762549  0.59086282]]\n",
      "b1:  (1, 8)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "W:  (8, 1)\n",
      "[[ 0.05003364]\n",
      " [-0.40467741]\n",
      " [-0.54535995]\n",
      " [-1.54647732]\n",
      " [ 0.98236743]\n",
      " [-1.10106763]\n",
      " [-1.18504653]\n",
      " [-0.2056499 ]]\n",
      "b:  (1, 1)\n",
      "[[0.]]\n",
      "\n",
      "PREDICTED\n",
      "[[0.95571182]\n",
      " [0.03954387]\n",
      " [0.95592983]\n",
      " [0.04574543]]\n",
      "ACTUAL\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Cost')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fd71128>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# holding cost for each iteration so that it can be plotted \n",
    "Jx = []\n",
    "\n",
    "# error threshold \n",
    "error_t = 0.001\n",
    "hiddenNodes = 8\n",
    "numIterations = 100000\n",
    "\n",
    "#alpha, input, hidden\n",
    "q3 = Network(0.001,2,hiddenNodes)\n",
    "\n",
    "i=0\n",
    "# while less than max iterations and all training samples have an error greater than 0.4\n",
    "while i < numIterations and np.greater(error,error_t).any():\n",
    "    error = q3.train(X, y)\n",
    "    cost = np.sum(np.power(error,2),axis=0)\n",
    "    Jx.append(cost)\n",
    "    i += 1\n",
    "\n",
    "# confirming that the correct patterns are predicted for the four test cases    \n",
    "print()\n",
    "print(\"PREDICTED\")\n",
    "print(q3.predict(X))\n",
    "print(\"ACTUAL\")\n",
    "print(y)\n",
    "\n",
    "plt.scatter([i for i,x in enumerate(Jx)], Jx)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Cost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Setting all weights to be larger than 5. With a learning rate of 0.001 and 100000 the error does not decrease. Changing the learning rate and number of hidden nodes seems to have little to no effect on the cost when the weights have values greater than 5. The output will always be a vector of ones because the sigmoid function is saturated. The gradients will always be close to zero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate:  0.001\n",
      "W1:  (2, 8)\n",
      "[[0.5507979  0.70814782 0.29090474 0.51082761 0.89294695 0.89629309\n",
      "  0.12558531 0.20724288]\n",
      " [0.0514672  0.44080984 0.02987621 0.45683322 0.64914405 0.27848728\n",
      "  0.6762549  0.59086282]]\n",
      "b1:  (1, 8)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "W:  (8, 1)\n",
      "[[ 0.05003364]\n",
      " [-0.40467741]\n",
      " [-0.54535995]\n",
      " [-1.54647732]\n",
      " [ 0.98236743]\n",
      " [-1.10106763]\n",
      " [-1.18504653]\n",
      " [-0.2056499 ]]\n",
      "b:  (1, 1)\n",
      "[[0.]]\n",
      "New Weights\n",
      "[[5.54464902 5.78031476 5.30636353 5.22195788 5.38797126 5.93638365\n",
      "  5.97599542 5.67238368]\n",
      " [5.90283411 5.84575087 5.37799404 5.09221701 5.6534109  5.55784076\n",
      "  5.36156476 5.2250545 ]]\n",
      "[[5.40651992]\n",
      " [5.46894025]\n",
      " [5.26923558]\n",
      " [5.29179277]\n",
      " [5.4576864 ]\n",
      " [5.86053391]\n",
      " [5.5862529 ]\n",
      " [5.28348786]]\n",
      "[[5.27797751 5.45462208 5.20541034 5.20137871 5.51403506 5.08722937\n",
      "  5.48358553 5.36217621]]\n",
      "[[5.70768662]]\n",
      "values from input to hidden\n",
      "[[10.82262652 11.23493684 10.51177388 10.42333659 10.90200632 11.02361302\n",
      "  11.45958095 11.03455989]\n",
      " [ 5.27797751  5.45462208  5.20541034  5.20137871  5.51403506  5.08722937\n",
      "   5.48358553  5.36217621]\n",
      " [11.18081162 11.30037295 10.58340439 10.29359572 11.16744596 10.64507013\n",
      "  10.8451503  10.58723072]\n",
      " [16.72546063 17.08068771 15.88976792 15.5155536  16.55541722 16.58145378\n",
      "  16.82114572 16.25961439]]\n",
      "sigmoid 1\n",
      "[[0.99998006 0.9999868  0.99997279 0.99997027 0.99998158 0.99998369\n",
      "  0.99998945 0.99998387]\n",
      " [0.99492317 0.99574172 0.99454314 0.99452122 0.99598636 0.99386279\n",
      "  0.99586278 0.99533121]\n",
      " [0.99998606 0.99998763 0.99997467 0.99996615 0.99998587 0.99997618\n",
      "  0.9999805  0.99997476]\n",
      " [0.99999995 0.99999996 0.99999987 0.99999982 0.99999994 0.99999994\n",
      "  0.99999995 0.99999991]]\n",
      "values from hidden to output\n",
      "[[49.33131517]\n",
      " [49.11800234]\n",
      " [49.33122168]\n",
      " [49.33213263]]\n",
      "sigmoid 2\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "dW\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "dW1\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1111bd6d8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Jx = []\n",
    "hiddenNodes = 8\n",
    "numIterations = 100000\n",
    "\n",
    "q3 = Network(0.001,2,hiddenNodes)\n",
    "# changing weights to be greater than 5\n",
    "q3.W1 = np.random.uniform(5,6,(2,hiddenNodes))\n",
    "q3.W = np.random.uniform(5,6,(hiddenNodes,1))\n",
    "q3.b1 = np.random.uniform(5,6,(1,hiddenNodes))\n",
    "q3.b = np.random.uniform(5,6,(1,1))\n",
    "print(\"New Weights\")\n",
    "print(q3.W1)\n",
    "print(q3.W)\n",
    "print(q3.b1)\n",
    "print(q3.b)\n",
    "i=0\n",
    "# while less than max iterations and all training samples have an error greater than 0.4\n",
    "while i < numIterations:\n",
    "    error = q3.train(X, y)\n",
    "    cost = np.sum(np.power(error,2),axis=0)\n",
    "    Jx.append(cost)\n",
    "    i += 1\n",
    "\n",
    "\n",
    "plt.scatter([i for i,x in enumerate(Jx)], Jx)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Cost\")\n",
    "\n",
    "print(\"values from input to hidden\")\n",
    "print(q3.z1)\n",
    "print(\"sigmoid 1\")\n",
    "print(q3.hidden)\n",
    "print(\"values from hidden to output\")\n",
    "print(q3.z2)\n",
    "print(\"sigmoid 2\")\n",
    "print(q3.output)\n",
    "print(\"dW\")\n",
    "print(q3.dW)\n",
    "print(\"dW1\")\n",
    "print(q3.dW1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
